\hsection{Floating Point Numbers}%
\label{sec:floats}%
%
In the previous section, we have discussed integers in \python.
One of the very nice features of the \python~3 language is that integers can basically become arbitrarily large.
There is only the single type \pythonil{int} and it can store any integer value, as long as the memory of our computer is large enough.%
%
\begin{sloppypar}%
In an ideal world, we would have a similar feature also for fractional numbers.
However, such a thing cannot be practically implemented.
You will certainly remember the numbers $\pi\approx3.141\decSep592\decSep653\decSep590\dots$ and $e\approx2.718\decSep281\decSep828\decSep459\dots$ from highschool maths.
They are transcendental~\cite{N1939TTOP,APM1991TOEAP,F2011TTOEAP}, i.e., their fractional digits never end and nobody has yet detected an orderly pattern in them.
Since these numbers are \inQuotes{infinitely long,} we would require infinitely much memory to store them \emph{if} we wanted to represent them \emph{exactly}.
So we don't and neither does \python.
We cannot really represent the real numbers~\realNumbers\ exactly in the memory of our computers.%
\end{sloppypar}%
%
\hsection{How Floating Point Numbers Work}%
\label{sec:howFloatingPointNumbersWork}%
%
\begin{figure}%
\centering%
\includegraphics[width=0.7\linewidth]{\currentDir/floatIEEEStructure}%
\caption{The structure of an 64~bit / double precision IEEE~Standard 754 floating point number~\cite{IEEE2019ISFFPA,H1997IS7FPN}.}%
\label{fig:floatIEEEStructure}%
\end{figure}%
%
But how does it work in \python?
How can we deal with the fact that we cannot dynamically represent fractional numbers exactly even in typical everyday cases?
With \pythonil{float}, \python\ offers us one type for fractional numbers.
This datatype represents numbers usually in the same format as \pythonil{double}s in the \pgls{C}~programming language~\cite{PSF2024NTIFC}, which, in turn, internally have a 64~bit IEEE~Standard 754 floating point number layout~\cite{IEEE2019ISFFPA,H1997IS7FPN}.
The idea behind this standard is to represent both very large numbers, like~$10^{300}$ and very small numbers, like~$10^{-300}$.
In order to achieve this, the 64~bits are divided into three pieces, as illustrated in \cref{fig:floatIEEEStructure}.
%
\noviceHint{%
You just need to understand that \pythonil{float}s have limited precision. %
You can jump right to the next section.}%
%
The first part, the so-called \pgls{significand} or \pgls{mantissa}, consists of 52~bits, represents the digits of the number.
52~bits can represent $52\log_2 10\approx 15$~decimal digits, meaning that we can represent numbers to a precision of about 15~digits.
If we would just use 52~bits, then this would limit us to represent numbers maybe from~$0$ to~$2^{52}-1$ at a resolution of~$1$.
Of course, we could also choose some other resolution, say~$0.001$.
In this case, we could represent numbers from~$0$ to $0.001*(2^{52}-1)$ and the smallest non-zero number would be~$0.001$ instead of~$1$.
Whatever fixed resolution we would choose, it would be good in some cases and bad in others.

Therefore, the second part of the 64~bit floating point number representation comes into play:
The 11~bits of the \pgls{exponent} represent a power of~2 which is multiplied to the \pgls{significand} to get the actual number.
In order to allow us to have both small and large numbers, this value must be able represent positive and negative exponents.
Therefore, the stored value of the \pgls{exponent} is taken and a \pgls{bias} of~1023 is subtracted.
Thus, a stored value of 2000 in the exponent fields leads to an actual exponent of $1050-1023=27$, which would mean that the \pgls{significand} is multiplied with~$2^{27}$, i.e., $134\decSep217\decSep728$.%
%
\begin{sloppypar}%
Finally, the \pgls{signBit} in the floating point number dataformat indicates whether the number is positive or negative.
Together, this allows us to represent numbers from $2.225\decSep073\decSep858\decSep507\decSep201\decSep4*10^{-308}$ to $1.797\decSep693\decSep134\decSep8623\decSep157*10^{308}$ with a resolution of approximately 15~digits.
Of course, the same range also applies to negative numbers and $0$~can be represented as well.
Indeed, there are even special floating point values for infinity and errors.
But more about this later.%
\end{sloppypar}%
%
Luckily, you will never really need to know these exact information.
The important thing to remember is:
Floating point numbers can represent a wide range of different values.
Their range is large but still limited.
They can represent integers and fractions.
However, their accuracy is always limited to about 15~digits.
In other words, regardless whether your \pythonil{float} stores a very large or a very small number, you can have at most 15~digits of precision.
For example, adding~1 to~$10^{16}$ would still yield~$10^{16}$, because only 15~digits are \inQuotes{stored} and the~1 will just \inQuotes{fall off.}
You cannot represent numbers arbitrarily precisely.%
\endhsection%
%
\hsection{Floating Point Arithmetic}%
%
\begin{figure}%
\centering%
\includegraphics[width=0.8\linewidth]{\currentDir/floatMathInConsoleArith}%
\caption{Basic arithmetics with floating point numbers in \python.}%
\label{fig:floatMathInConsoleArith}%
\end{figure}%
%
Floating point numbers in \python\ can be distinguished from \pythonil{ints} by having a decimal dot in their text representation, i.e., \pythonil{5.0} is a \pythonil{float} and \pythonil{5} is an \pythonil{int}.
Let us now look at some examples for the basic arithmetic operations available for \pythonil{float}s in \cref{fig:floatMathInConsoleArith}.

We already learned that the division operator~\pythonil{/} always yields a \pythonil{float} result.
Therefore \pythonil{6 / 3} yields \pythonil{2.0} instead of \pythonil{2}.

The normal arithmetic operations like addition, subtraction, multiplication, division, and powers all work with \pythonil{float}s as expected.
Remember, however, that if \pythonil{float} and \pythonil{int} numbers are mixed, the results are always \pythonil{float}s.
Thus, \pythonil{1.0 + 7} gives us \pythonil{8} and \pythonil{2 * 3.0} yields \pythonil{6.0}.
In other words, if one \pythonil{float} occurs somewhere in an expression, it will \inQuotes{infect} everything that it touches to become a \pythonil{float} too, even if the result could be repreented as \pythonil{int}.
Some results cannot be integers anyway, for example \pythonil{5 - 3.6} evaluates to~\pythonil{1.4}.
The remainder (the modulo) of a division can also be computed for floating point numbers.
The remainder of the division of 6.5 by 2, i.e., \expandafter\pythonil{6.5 \% 2} is \pythonil{0.5}.

The square root of 3.3 can be computed as $3.3^{0.5}$.
\pythonil{3.3 ** 0.5} yields \pythonil{1.816590212458495}.
This brings us back to the previous section:
$\sqrt{3.3}$~is not actually 1.816\decSep590\decSep212\decSep458\decSep495.
It is an irrational number~\cite{S1988WPCHD,B1991IWNT} and irrational numbers cannot be expressed as fractions of integer numbers (by definition, otherwise they would be rational numbers).
Since they cannot be expressed as integer numbers, we cannot write them in any way like $\frac{1\decSep816\decSep590\decSep212\decSep458\decSep495\dots}{1\decSep000\decSep000\decSep000\decSep000\decSep000\dots}$, regardless of how large a denominator we would pick.
Hence, we cannot represent them exactly using discrete binary values of our computer's memory.
Hence, the floating point representation cuts off somewhere.
And this somewhere is after 15~decimal places.%
%
\begin{sloppypar}%
We can of course also write and compute more complex mathematical expressions.
\pythonil{((3.4 * 5.5) - 1.2) ** (4.4 / 3.3)} corresponds to $((3.4*5.5)-1.2)^{\frac{4.4}{3.3}}$ and yields \pythonil{45.43432339119718}.
This is again not an exact value but a rounded value.
We always need to keep this in mind.%
\end{sloppypar}%
%
Let us recall our initial example of the transcendental irrational numbers~$\pi$ and~$e$.
Certainly, these are very important constants that would be used in many computations.
We can make them accessible in our code by importing them from the \pythonil{math} module.\footnote{%
We will learn about these mechanism in detail later on.}
This can be done by typing \pythonil{from math import pi, e}.
When we then type \pythonil{pi} and \pythonil{e}, we can get to see their value in floating point representations: \pythonil{3.141592653589793} and \pythonil{2.718281828459045}, respectively.
Again, these are not the exact values, but they are as close as we can get in this format.

Of course, $\pi$ and~$e$ alone are not that much useful.
If you reach back into your highschool days again, you will remember many interesting functions that are related to them.
Let us import a few of them, again from the \pythonil{math} module, via \pythonil{from math import sin, cos, tan, log}.
I think you can guess what these functions do.

From highschool, you may remember that~$\sin{\frac{\pi}{4}}=\frac{\sqrt{2}}{2}$ and thus~$\sin^2{\frac{\pi}{4}}=0.5$.
Let us compute this in \python\ by doing \pythonil{sin(0.25 * pi) ** 2}.
Surprisingly, we get \pythonil{0.4999999999999999} instead of \pythonil{0.5}.
The reason is again the limited precision of \pythonil{float}, which cannot represent~$\frac{\sqrt{2}}{2}$ exactly.
Similarly, $\cos{\frac{\pi}{3}}=\frac{1}{2}$ but \pythonil{cos(pi / 3)} yields \pythonil{0.5000000000000001} and $\tan{\frac{\pi}{4}}$ expressed as \pythonil{tan(pi / 4)} returns \pythonil{0.9999999999999999} instead of~$1$.
Then again, these values are incredibly close to the exact results.
They are off by \emph{less than~$10^{-15}$} so for all practical concerns, they are close enough.
Sometimes, we even get the accurate result, e.g., when computing $\ln(e^{10})$ by evaluating \pythonil{log(e ** 10)}, which results in~\pythonil{10.0}.

As final example for floating point arithmetics, let us import the inverse trigonometric functions by doing \pythonil{from math import asin, acos, atan}.
Obviously, $\arcsin{\sin{0.925}}$ should be~$0.925$.
Calculating \pythonil{asin(sin(0.925))} indeed yields~\pythonil{0.9250000000000002}.
Due to the periodicity of the trigonometric functions, $\arccos{\cos{-0.3}}$ is~$0.3$ and \pythonil{acos(cos(-0.3))} results in~\pythonil{0.30000000000000016}.
For $\arctan{\tan{1}}$ we even get the exact result \pythonil{1.0} by computing \pythonil{atan(tan(1))}.%
\endhsection%
%
\hsection{The Scientific Notation}%
%
\begin{figure}%
\centering%
\begin{tabular}{r@{}r@{{\color{orange}\textbf{e}}}l@{~~$\equiv$~~}r@{}l}%
\multicolumn{2}{c}{$\beta$}&$\gamma$&\multicolumn{2}{c}{$\alpha$}\\\hline%
&\texttt{A.BCDEFG}{\dots}&\texttt{\color{red}{+}}\texttt{HIJ}&&$\texttt{A.BCDEFG}{\dots}*10^{HIJ}$\\
&\texttt{A.BCDEFG}{\dots}&\texttt{\color{red}{-}}\texttt{HIJ}&&$\texttt{A.BCDEFG}{\dots}*10^{{\color{red}{-}}HIJ}$\\
{\color{blue}{-}}&\texttt{A.BCDEFG}{\dots}&\texttt{\color{red}{+}}\texttt{HIJ}&${\color{blue}{-}}$&$\texttt{A.BCDEFG}{\dots}*10^{HIJ}$\\
{\color{blue}{-}}&\texttt{A.BCDEFG}{\dots}&\texttt{\color{red}{-}}\texttt{HIJ}&${\color{blue}{-}}$&$\texttt{A.BCDEFG}{\dots}*10^{{\color{red}{-}}HIJ}$%
\end{tabular}%
%
\caption{The structure of the scientific notation for floating point numbers in \python, which represent a value~$\alpha$ in the form~$\beta*10^{\gamma}$.}%
\label{fig:scientificNotation}%
\end{figure}%
%
\begin{figure}%
\centering%
%
\includegraphics[width=0.8\linewidth]{\currentDir/floatMathInConsoleSciNot}%
\caption{Examples for the scientific notation in \python.}%
\label{fig:floatMathInConsoleSciNot}%
\end{figure}%
%
Earlier on, we wrote that \pythonil{float}s can represent numbers as large as~$10^{300}$ or as small as~$10^{-300}$.
This leads to the question how it would print such values on the console and how we can read them.
While it would be hugely impractical to write a~1 followed by 300~zeros to represent~$10^{300}$, it would also be \emph{wrong}.
We also already know the reason for this:
A \pythonil{float} is accurate to 15~decimals.
So basically, the first 15~zeros would be correct, but the values of the other digits are actually \emph{undefined}.

\python, like many programming languages, solves this problem by using the \emph{scientific notation} for floating point numbers.
It uses this notation for any (absolute) \pythonil{float} value smaller than~$10^{-4}$ or larger than or equal to~$10^{16}$.
Such numbers~$\alpha$ are then represented in the form~$\beta*10^{\gamma}$ (such that $\beta*10^{\gamma}=\alpha$, obviously).
Since we cannot write this so nicely in a console, a lowercase~\texttt{e} takes the place of the~$10$ and $\beta$ and $\gamma$ are written as normal text.
In order to make sure that each number~$\alpha$ has unique representation, it is defined that $\alpha$ must have exactly one non-zero leading digit, which may be followed by a decimal dot and then a fractional part.
This notation is illustrated in \cref{fig:scientificNotation}.
\emph{This notation only applies to \pythonil{float}s, \textbf{not} \pythonil{int}s.}

In \cref{fig:floatMathInConsoleSciNot} we provide some examples for this notation.
When we write \pythonil{0.001} or \pythonil{0.0001} in a \python\ console, the output is still this same number.
However, \pythonil{0.00009} is presented as \pythonil{9e-05}, which stands for~$9*10^{-5}$.%
%
\begin{sloppypar}%
Did you know that you are allowed to insert underscores (\pythonil{_}) anywhere in a number as a visual aid?
If not, you know now.
We can write $10^{15}$ as \pythonil{float} by typing \pythonil{1_000_000_000_000_000.0}.
This equals the much less readable \pythonil{1000000000000000.0}.
We can do the same for $9*10^{15}$ by writing \pythonil{9_000_000_000_000_000.0} and get \pythonil{9000000000000000.0}.
However, if we write \pythonil{9_999_999_999_999_999.0}, something interesting happens:
We get \pythonil{1e+16}, i.e., $10^{16}$.
This is because of the limited precision of the floating point numbers, namely the 15~digits often mentioned above.
We cannot distinguish $10^{16}$ and $10^{16}-1$ when using \python's \pythonil{float}s.
Indeed, writing \pythonil{10_000_000_000_000_000.0} also yields \pythonil{1e+16}.%
\end{sloppypar}%
%
This notation can also show really big numbers.
For example $10^{200}$, i.e., \pythonil{10.0 ** 200}, shows up as \pythonil{1e+200}.
The really really small number $-10^{-200}$ in turn, computed via \pythonil{-(10.0 ** -200)}, is denoted as \pythonil{-1e-200}.

The numbers are always scaled such that they begin with non-zero digit followed by the fractional part separated with a decimal dot, if need be.
Examples for this are \pythonil{2.1 ** -300.1} which yields \pythonil{2.0044242594658263e-97} and \pythonil{10.0 ** 200.1}, which turns up as \pythonil{1.2589254117941507e+200}.

Of course, you can also input numbers in scientific notation.
If you write \pythonil{2e5}, this turns into \pythonil{200000.0}.
Of course, the number is stored as a \pythonil{float} internally and this \pythonil{float} does not know from which kind of text it was created.
When it is turned back into text, it becomes a \inQuotes{normal number,} because it is less than~$10^{16}$.
And so does \pythonil{2.34e10}, which becomes \pythonil{23400000000.0}.
\pythonil{2.3456e16} however indeed remains \pythonil{2.3456e16}.

You can even violate the scientific notation a bit when entering numbers if you feel naughty.
\pythonil{-12e30}, for example, would better be written as \pythonil{-1.2e+31}, which the \python\ console will do for you in its output.
Similarly, \pythonil{0.023e-20} becomes \pythonil{2.3e-22}.
\endhsection%
%
\endhsection%
%
