\hsection{Functions}%
%
Functions are blocks of code that can be invoked from anywhere else in a program.
You already learned many functions, from the basic \pythonilIdx{print} routine that just prints the value of its parameter to the output to the \pythonilIdx{sqrt} function from the \pythonilIdx{math} module which computes the square root.
Now you will learn how to make your own functions~\cite{PSF:P3D:TPT:MCFT}.%
%
\hsection{Defining and Calling Functions}%
\label{sec:definingFunctions}%
%
We distinguish the definition and the invocation of a function.
The function definition is where we specify the name, parameters, return value, and the body of code of a function.
The function invocation is where we actually use the function.
We can \emph{invoke}, also known as \emph{call}, from anywhere in our code by using its name.
We then have to supply the values for its parameters and can receive the return value, e.g., in a variable.
\pythonIdx{def}\pythonIdx{function!def}%
The syntax for defining our own functions in \python\ is as follows:%
%
\pythonSyntax{syntax/function.py}%
%
\pythonIdx{function!def}A function in \python\ is created by using the \pythonilIdx{def}\pythonIdx{function!def} keyword, followed by the name of the function.%
%
\bestPractice{functionNames}{Function names should be lower case, with underscores separating multiple words if need be~\cite{PEP8}.}%
%
\pythonIdx{function!parameter}After the function name follows an opening and a closing parenthesis, i.e., \pythonil{(...)}\pythonIdx{(\idxdots)}.
A function can have parameters through which we can pass values to it.
In case of the \pythonil{print} function, this was the string to be printed.
In case of the \pythonil{sqrt} function, this was the number to compute the quare root of.
Inside the function, these parameters act like variables.
The values of these variables can be passed in when we call (invoke, execute) the function.
The values thus stem from the code that calls the function.%
%
\begin{definition}[Parameter]\pythonIdx{function!parameter}%
A function \emph{parameter} is a variable defined inside the function that receives its value from the calling code when the function is called.%
\end{definition}%
%
The parameters of a function are written between the opening and closing parentheses in the function header.
Each parameter has a name, which is the name under which it can be accessed inside the function.
The parameters are separated by commas.
We can specify arbitrarily many parameters or no parameter at all.
Notice that, just like variables, all such parameters should be annotated with \pglspl{typeHint}~(see \cref{sec:variableTypesAndTypeHints})~\cite{PEP3107}.
This is especially important:
You do want that users of your function can clearly understand whether they can pass integers, strings, or floating point numbers as parameter values to your function or not.
If we define a function \pythonil{add(value_1, value_2)}, it would not be clear at all what datatypes we can pass in for \pythonil{value_1} and \pythonil{value_2}.
With \pglspl{typeHint} like \pythonil{add(value_1: int, value_2: int)}, it will be very clear.

Functions can return results~(like the \pythonilIdx{sqrt} function of the \pythonilIdx{math} module does) or return nothing~(like \pythonilIdx{print}).
\pythonIdx{function!return value}If they return a result, the type of this result should be specified.
This is done with the \pgls{typeHint} \pythonil{ -> result_type}\pythonIdx{->} following the closing parenthesis in the function header.%
%
\begin{definition}[Signature]%
The sequence of parameter types and the return type of a function together are called the \pgls{signature}\pythonIdx{function!signature} of the function.%
\end{definition}%
%
The function header ends with a colon~(\pythonilIdx{:}).%
%
\bestPractice{functionTypeHints}{\pythonIdx{function!type hint}%
All parameters and the return value of a function should be annotated with \pglspl{typeHint}~\cite{PEP3107}. %
From my perspective: \emph{A function without \pglspl{typeHint} is wrong.}%
}%
%
After the function header, indented by four spaces, follows the function body.%
%
\bestPractice{functionBodyIndentation}{The body of a function is indented with four spaces.}%
%
\pythonIdx{function!body}The function body can be an arbitrary block of code, which may contain all the things we already learned.
From \pythonil{if...else} over \pythonil{for} and \pythonil{while} loops to variable assignments can calls to other functions, all can be used.

When a function is called, this code block is executed.
When the end of the block is reached, the function automatically exists without returning any value.
At that point, the control flow resumes in the code that called the function, right after the function call.
\pythonIdx{function!return}The function can also be exited at any point by using the \pythonilIdx{return} statement.
If the function is supposed to return a value \pythonil{result}, then this is done via \pythonil{return result}.
Notice that, like the \pythonilIdx{break} statement in loops, we can place \pythonilIdx{return} at any location we want.
We can also have multiple \pythonilIdx{return} values at different places in the function.%
%
\begin{sloppypar}%
\pythonIdx{function!call}The function \pythonil{my_function} then can be called from anywhere in the code by writing \pythonil{my_function(value_1, value_2)}.
Here, \pythonil{value_1} is passed in as value of \pythonil{param_1} and \pythonil{value_2} is passed in as value of \pythonil{param_2}.
This follows the same pattern of function calls that we already used in many of our examples.%
\end{sloppypar}%
%
\begin{definition}[Argument]\pythonIdx{function!argument}%
An \emph{argument} is the actual value given for a function parameter when the function is called.%
\end{definition}%
%
\pythonIdx{function!docstring}\pythonIdx{str!doc!function}%
Between the header of a function and its body, we always need to place a so-called \pgls{docstring}, which is a multi-line string~(see \cref{sec:multiLineStrings}).
This string consists of a title line shortly describing what the function does.
Then follows an empty line.
After that, we can (but not necessarily need to) place paragraphs of text providing a more detailled discussion.
Then follows the list of parameters, each in the syntax \textil{:param parameter_name: description}\pythonIdx{:param:}.
Then follows the return value description (if the function returns something) in the form \textil{:returns: description}\pythonIdx{:returns:}.%
%
\bestPractice{funcDocstrings}{%
Each function should be documented with a \pgls{docstring}. %
If you work in a team or intend to place your code in public repositories like on \pgls{github}, then this very very much increases the chance that your code will be used correctly. %
From my perspective: \emph{A function without \pgls{docstring} is wrong.}%
}%
%
\bestPractice{functionSpace}{%
After the function and its body are defined, leave \emph{two} blank lines before writing the next code~\cite{PEP8}.%
}%
%
\gitLoadAndExecPython{functions:def_factorial}{}{functions}{def_factorial.py}{}%
\listingPythonAndOutput{functions:def_factorial}{%
Implementing a function computing the factorial of a positive integer number.}{}%
%
Now we know the general scheme based on which functions can be defined.
After all of this long introduction, let us finally come to some example.
Let's implement the factorial function as, well, function.
The factorial is defined as follows~\cite{D1991TEHOTFF,CB2022FBDOTFF}%
%
\begin{equation}%
\factorial{a}=\left\{\begin{array}{rl}%
1&\textnormal{~if~}a = 0\\%
\prod_{i=1}^a i&\textnormal{~otherwise, i.e., if~}a>0%
\end{array}\right.%
\label{eq:factorial}%
\end{equation}%
%
where $\prod_{i=1}^a i$ stands for the product~$1*2*3*\dots*(a-1)*a$.
We will implement this function in \python\ call it \pythonil{factorial} in \cref{lst:functions:def_factorial}.
So we begin the header of our function a \pythonil{def factorial(}\pythonIdx{def}.
It should receive a single parameter~\pythonil{a}, so we write it into the parentheses.
\pythonil{a} will be type-hinted as integer via \pythonil{a: int}.
The result of our function will be an integer as well, so we add the \pgls{typeHint} \pythonil{-> int}.
The header of our function is ends with the colon~\pythonil{:} and is thus \pythonil{def factorial(a: int) -> int:}.

The body of this function is straightforward.
We begin by initializing a variable \pythonil{product} with the value~\pythonil{1}.
Then, we need a loop that iterates a variable~$i$ over all positive integers less than or equal to~\pythonil{a}.
We want to multiply these values to~\pythonil{product}.
Well, we can skip over~$\pythonil{i}=1$, because that would be useless.
So we will use a \pythonilIdx{for} loop iterating~\pythonil{i} over the \pythonil{range(2, a + 1)}\pythonIdx{range}.
This effectively starts~\pythonil{i} at~\pythonil{2}.
Since the upper limit~\pythonil{a + 1} of the \pythonilIdx{range} is always \emph{exclusive}, the last value for~\pythonil{i} will be~\pythonil{a}.
Notice that we really use \pythonil{a} like a normal variable that was assigned a value.%
%
\begin{sloppypar}%
Anyway, inside the loop body, we compute \pythonil{product *= i}\pythonIdx{*=}, which is equivalent to \pythonil{product = product * i}.
After the loop, \pythonil{product} holds $\factorial{\pythonil{a}}$.
So we can return it as the result of the function, by writing \pythonil{return product}\pythonIdx{return}.%
\end{sloppypar}%
%
We can now compute the factorial of any positive integer number~\pythonil{x} by calling~\pythonil{factorial(x)}.
After the function body, we leave two empty lines.
And then we compute the factorials of the numbers from~$1$ to~$9$ in a \pythonilIdx{for}-loop and print them by using \pglspl{fstring}.
Inside this loop and in the \pgls{fstring}, we can use the function \pythonil{factorial} exactly like any other function we used before, like \pythonil{sqrt} or \pythonil{sin}.
It may be an interesting side information at the end of this example that the factorial can actually be computed \emph{faster} than using this product form, see, e.g.~\cite{L2015ANKOFF}.

Functions can have a more than one parameter or no parameter at all.
They can return one value or return nothing at all\footnote{%
We already learned that if they return nothing, they actually return \pythonilIdx{None} back in \cref{sec:none}.%
}.
Functions can also be called from other functions.

\begin{figure}%
\centering%
\tightbox{\includegraphics[width=0.5\linewidth]{\currentDir/euclidOfAlexandria}}%
\caption{An illustration of Euclid of Alexandria, \href{https://www.antike-griechische.de/Euklid.pdf}{attributed} to the painter Charles Paul Landon~(1760--1826). Source:~\href{https://fr.vikidia.org/wiki/Cat\%C3\%A9gorie:Image_Euclide}{Vikidia}, where it is noted as \emph{domaine public,} i.e., as in the Public Domain.}%
\label{fig:euclidOfAlexandria}%
\end{figure}%
%
\gitLoadAndExecPython{functions:def_gcd}{}{functions}{def_gcd.py}{}%
\listingPythonAndOutput{functions:def_gcd}{%
Implementing the Euclidean Algorithm as a function and calling it from another function.}{}%

Let us investigate these options by investigating another interesting mathematical operation:
The computation of the greatest common divisor, also known as~\pythonil{gcd}.
This can be done using the Euclidean algorithm~\cite{EHF2008EEOGTGOJLH11FEEEELIEILHIATBG11EAPWMETBFR:ENT,B1999FAOTBEA,TKY2016BEOEAOTCEG}, going back to \citeauthor{EHF2008EEOGTGOJLH11FEEEELIEILHIATBG11EAPWMETBFR:ENT} who flourished about 300~\pgls{BCE} and is sketched in \cref{fig:euclidOfAlexandria}.

The greatest common divisor of two numbers positive~$a\in\naturalNumbersO$ and~$b\in\naturalNumbersO$ is the greatest number~$g\in\naturalNumbersO=\pythonil{gcd}(a,b)$ such that~$a\bmod g=0$ and~$b \bmod g=0$, where~$\bmod$ is the \pgls{modulodiv} operator, i.e., the rest of a division, which, in turn, is equivalent to \python's~\pythonilIdx{\%}.
This means that $g$~divides both $a$ and $b$ without remainder.
If $a=b$, then obviously $\pythonil{gcd}(a,b)=a=b$ as well.
Otherwise, we know that $a=ig$ must be true for some~$i\in\naturalNumbersO$ and $b=jg$ will hold for some~$j\in\naturalNumbersO$.

Let us assume, without loss of generality, that~$a>b$.
Then, $c=a-b=(i-j)g$.
It is clear that $c\bmod g=(a-b)\bmod g=(i-j)g\bmod g = 0$ must be true, too.
It also holds, obviously, that~$a-b < a$.
Similarly, we could use the division remainder~$d$ instead of the difference~$c$:
$d=a\bmod b=ig\bmod (jg)=ig-\lfloor i/j\rfloor*jg=g(i-j\lfloor i/j\rfloor)$ is still divisible by~$g$ without remainder as~$d\bmod g=0$.
And it is also true that~$a\bmod b < a$.

Since both~$d$ and~$c$ are less than~$a$ \emph{and} divisible by~$g$, we could replace~$a$ with either of them.
The cool thing about~$d$ is that $d$~will be less than both~$a$ and~$b$.
This means that we could replace the old~$a$ with~$b$ and store $d$ in the variable~$b$.

If we keep repeating these computational steps, then our values will become smaller and smaller.
But they will always be both divisible by~$g$.
We would repeat this until reaching~$b=0$, at which point~$a$ will be~$g$.
Matter of fact, by choosing the module-based update, we do not even need to assume that~$a>b$.
Because if~$b>a$, then~$a \bmod b=a$ and we would just switch~$a$ and~$b$ in the first step.
If~$a=b$, then~$a \bmod b=0$ and we would immediately terminate after the first step and return~$a$ as the greatest common divisor.

This algorithm is implemented in file \programUrl{functions:def_gcd} given in \cref{lst:functions:def_gcd} as function~\pythonil{gcd}.
Our new function \pythonil{gcd} has two integer parameters, \pythonil{a} and~\pythonil{b}.
It returns another~\pythonil{int}.
Notice the proper \pglspl{typeHint} in the function header.
After the function header, we place a \pgls{docstring} describing the function, its parameters, and its return value.

The function body is surprising short:
We use a \pythonilIdx{while} loop that iterates as long as \pythonil{b > 0}.
After the loop, we \pythonil{return a}\pythonIdx{return} as the result.
If \pythonil{b == 0} holds at the beginning, the loop will never be executed and~\pythonil{a} is returned as-is, which is correct:
$\pythonil{gcd}(a, 0)=a$ for all~$a\in\naturalNumbersO$.

However, if \pythonil{b > 0}, we enter the loop's body, which is a single line of code:
the multi-assignment (or tuple-unpacking) command~\pythonil{a, b = b, a \% b}.\pythonIdx{tuple!unpacking}\pythonIdx{unpacking}
It works approximately like this:
This line first completely evaluates the right-hand side.
This creates a tuple\pythonIdx{tuple} where the first value is~\pythonil{b}.
The second value is~\pythonil{a \% b}.
The tuple is then unpacked and stored in the variables~\pythonil{a} and~\pythonil{b}.
\pythonil{a} will thus receive the value that \pythonil{b}~had during the evaluation of the right-hand side.
\pythonil{b} will receive the previously computed value of~\pythonil{a \% b}.
In other words, \pythonil{b} is stored in~\pythonil{a} and the remainder of the division of the old \pythonil{a} by the old \pythonil{b} is stored in~\pythonil{b}.
Clearly, \pythonil{b} will become smaller in each iteration.
Since it can never become negative, it will eventually reach~\pythonil{0}.
Then the loop will terminate.
Similarly, the \emph{gcd} is never \inQuotes{lost} during the loop.
It will be the value in~\pythonil{a} at the end.
And this value is returned.

So with \pythonil{gcd}, we implemented a function with two parameters and one return value.
Let us now implement a second function, this time with no return value.
Our function \pythonil{print_gcd} accepts again two parameters~\pythonil{a} and~\pythonil{b}.
However, it returns nothing.
Instead, it will print the \pythonil{gcd} nicely using \pythonilIdx{print} and an \pgls{fstring}.
Of course, we properly annotate it with \pglspl{typeHint} and also give it a proper \pgls{docstring}.

The \pythonilIdx{math} module also provides a function names \pythonilIdx{gcd}.
It, too, computes the greatest common divisor.
Naturally, we want to compare the result of our function with this one.
%
\begin{sloppypar}\pythonIdx{function!import}%
Of course, we cannot have two functions named \pythonil{gcd} in the same context.
So we import the function from the \pythonilIdx{math} module \emph{under a different name}:
\pythonil{from math import gcd as math_gcd}\pythonIdx{as}\pythonIdx{import}\pythonIdx{from} makes the \pythonilIdx{gcd} function from the module \pythonilIdx{math} available under the name~\pythonil{math_gcd}.
And we use it in the \pgls{fstring} in \pythonil{print_gcd} under that name.%
\end{sloppypar}%
%
Finally, we confirm that \pythonil{gcd} and \pythonil{math_gcd} compute the same result for four test cases at the bottom of our program.
Now that all is said and done, it should be mentioned that the Euclidean Algorithm has a particularly efficient binary variant which is faster than our implementation in \cref{lst:functions:def_gcd}.
This binary variant may have been developed in China in the first century~\pgls{CE}~\cite{B1999FAOTBEA}.

We are now able, to implement our own functions.
We can properly annotate them with \pglspl{typeHint} and \pglspl{docstring}.
We can thus define re-usable blocks of code that can be called from multiple, arbitrary places in other code.
And we can make them available as units that can be used by others who understand their documentation.
Nice.%
%
\FloatBarrier%
\endhsection%
%
\hsection{Functions in Modules}%
\label{sec:functionsInModules}%
\pythonIdx{module!import}\pythonIdx{function!import}\pythonIdx{function!module}%
%
\gitLoadPython{functions:my_math}{}{functions/my_math.py}{}%
\listingPython{functions:my_math}{%
The module \pythonil{my_math}, which provides two mathematics functions, namely \pythonil{sqrt}, implementing the algorithm of Heron to compute the square root from \cref{lst:loops:while_loop_sqrt}, and \pythonil{factorial}, copied from \cref{lst:functions:def_factorial}.}%
%
You may not have noticed it, but we just made a very big step in our programming skills.
We moved from simple programs which only consist of one big block of code to modular programs.
We can now reuse code.
When we began our journey, we typed all commands into the \python\ interpreter and executed them one by one.
Then we became able to write our code into files, which allowed us to execute the same program several times.
Now we can even structure the code into functions, which we can explain via \pglspl{docstring} and annotate with \pglspl{typeHint}.
We can alreay write useful and reasonably large programs
However, so far, all of our programs in their entirety are stored in single files.

This puts a certain limit on the complexity of the applications that we can realize.
After a few thousand lines of code in a single file and maybe a few dozens of functions, it will become very hard to keep track of what is what and where.
This limit can easily be broken if we can group different types of functionality into different files.

We will therefore now learn how to distribute code over multiple files.
This answers two main questions:
How can we avoid writing our applications as a single, huge, and unstructured file which would be impossible to maintain in the long run?
How can we divide our application into smaller units that we can test, improve, and maintain separately and maybe use and reuse in different contexts?
A big part of the answer to this question are \emph{modules} and \emph{packages}~\cite{PSF:P3D:TPLR:TIS}.

For all intents and purposes within this book, a \emph{module}\pythonIdx{module} is a \python\ file and a \emph{package}\pythonIdx{package} is a directory wherein such files are located.
As described in~\cite{PSF:P3D:TPLR:TIS}, modules do not necessarily need to be files and packages can probably be created otherwise as well, but let us keep it simple here.

Indeed, we have already worked with modules, most prominently the~\pythonilIdx{math} module.
This module is basically a collection of mathematical functions.
Since we have implemented several mathematical functions by ourselves, let us put some of them in a module as well.

In \cref{lst:functions:my_math} we do just that.
We create the \python\ file \programUrl{functions:my_math} and place two functions into it:
The function \pythonil{factorial} from \cref{lst:functions:def_factorial} and a new function called \pythonil{sqrt}.
The \pythonil{sqrt} function basically encapsulates our code from back in \cref{lst:loops:while_loop_sqrt}, where we implemented the Heron's Method to compute the square root, as a function.
Now, \pythonil{number}, the input of this algorithm, comes in as a parameter.%
%
\bestPractice{packageAndModuleNames}{Package and module names should be short and lowercase. Underscores can be used to improve readability.~\cite{PEP8}}%
%
Our new module has the name \textil{my_math}, because it is in file \programUrl{functions:my_math}.
It does not look very special or different from what we did so far.
The one difference that we notice, however, is that it \inQuotes{does nothing}.
In the file, we define two functions, but we do not actively call them, we do not use them for anything.
This is the purpose of this module:
It just provides the functions.
We will use them elsewhere.

\gitLoadAndExecPython{functions:use_my_math}{}{functions}{use_my_math.py}{}%
\listingPythonAndOutput{functions:use_my_math}{%
A program using the functions \pythonil{sqrt} and \pythonil{factorial} from the module \pythonil{my_math} given in \cref{lst:functions:my_math}.}{}%
%
\begin{sloppypar}%
And \cref{lst:functions:use_my_math} is where we use them:
We write a program, i.e., another \python\ file, named \programUrl{functions:use_my_math}.
In this file, we want to use our two functions \pythonil{factorial} and \pythonil{sqrt} from the module \pythonil{my_math}.
For this purpose, we have to tell the \python\ interpreter where it can find these two functions.
We do this by writing \pythonil{from my_math import factorial, sqrt}\pythonIdx{from}\pythonIdx{import}\pythonIdx{module}.
The meaning of the line is quite obvious:
There is a module \pythonil{my_math} \pythonilIdx{from} which we want to \pythonilIdx{import}, i.e., make available, two functions, namely \pythonil{factorial} and \pythonil{sqrt}.%
\end{sloppypar}%
%
Now, the \python\ interpreter knows a lot of modules.
Several modules ship with any \python\ installation, like \pythonilIdx{math}.
Others are installed via a package manager like \pgls{pip}~\cite{PSF:P3D:IPM}~(we will eventually discuss this in-depth later).
The \pythonil{my_math} module is found because it is in the same directory as the program \programUrl{functions:use_my_math}.

We could have placed the \programUrl{functions:my_math} file into a sub-directory named \textil{math_pack} instead.
Thenm we would import our functions from \textil{math_pack.my_math}, where \textil{math_pack} would be called a~\emph{package}.
Of course, we could also create another level of directories, say we could have directory \textil{utils}, containing directory \textil{math_pack}, containing our file \programUrl{functions:my_math}.
In this case, we would import our functions like \pythonil{from utils.math_pack.my_math import}\dots.
The names of package and modul are separated by a~\pythonilIdx{.} when importing from them.
This allows us to nicely and hierarchically structure our projects into modules and packages for different purposes.

In \cref{lst:functions:use_my_math} we can use both \pythonil{sqrt} and \pythonil{factorial} exactly as if we had defined them in this program.
We first print a few values for \pythonil{sqrt} and \pythonil{factorial} and also show that we can compute the result of the square root of a factorial.
We also just copy the code from \cref{lst:loops:for_loop_pi_liu_hui}, where we use the method of LIU Hui~(刘徽) method to approximate~\numberPi\ -- but this time, we use our own implementation of the square root function instead of the one from the \pythonil{math} module.
Interestingly, the sixth and last approximation step in \cref{exec:functions:use_my_math} shows exactly the same result as in \cref{exec:loops:for_loop_pi_liu_hui}.

Ever since we became able to use \pythonil{while} loops, we had the basic means to implement \emph{any} function that our computers can compute.
However, we were limited on a technical level.
Theoretically, we could have implemented an arbitrarily complex program.
However, without functions, we would probably have very repetitive~(and therefore, long) code.
Without modules, we would have ended up with one giant, unreadable, unmaintainable file.

We now broke through these limitations.
We can create reusable code by writing functions.
We can group functions with similar tasks into modules.
We even can place modules with similar domains into the same package and such with another domain into another one.
We are now able to implement well-structured and maintainable software.%
%
\FloatBarrier%
\endhsection%
%
\hsection{Interlude:~Unit Testing}%
\label{sec:unitTesting}%
\pythonIdx{function!unit test}%
\pythonIdx{function!testing}%
%
Structuring our code into functions and modules has several advantages.
We can reuse code and we can divide big application into smaller pieces, both of which make it easier to understand what our program is doing.
Or is \emph{supposed} to be doing.
Because errors happen in programming.
They happen often and they happen naturally.
And bigger programs are more likely to contain errors, and more likely to contain more errors than smaller programs.

We are now at a stage where we can design almost arbitrarily large programs, which are well-structured and maintainable.
We are not limited anymore at the architectural level.
However, our goal is not to just design large maintainable software {\dots} we also want it to be correct and reliable.

Imagine that you have a big application consisting of unstructured code for reading and writing files, code for making mathematical computations, and so on.
Then, it would not easy to figure out how to check whether the big application behaves exactly as it is supposed to.
There would be too many combinations of inputs and environments and conditions that we would need to test.
And even if we would find that the application behaves incorrectly in a few cases.
Then what?
It would be very hard to figure out which of its many interacting lines of code causes the error.

Here, dividing code into functions and placing it into modules has yet another advantage:
We now have smaller units of code -- the functions -- that we can test separately.
It is much easier to check whether our \pythonil{factorial} and \pythonil{sqrt} functions behave as we expect them than to do this for a whole complex program.%
%
\begin{definition}[Unit Testing]
\label{def:unitTesting}%
\glslink{unitTest}{\emph{Unit Testing}} is a software testing technique where separate components or functions of an application are tested in isolation~\cite{P2021PUTAAOAEUTIP,R2006ASOUTP,TLG2006UTCU,O1991UTVIT,B2004JPG,O2003UTTETO}.%
\end{definition}%
%
This idea works hierarchical.
We implement and test the smallest functions~$\mathcal{A}$.
We \inQuotes{code a little, test a little}~\cite{BG2000TIPLWT}, allowing us to both understand and verify our code.
Then we move on.
We implement and test the functions~$\mathcal{B}$ that use these smaller functions~$\mathcal{A}$.
We implement and test the functions~$\mathcal{C}$ that use the functions~$\mathcal{B}$~(and maybe also~$\mathcal{A}$).
We work our way up, from implementing and testing the smallest, most primitive pieces of code at the lowest level of our application, to the most abstract code at the top-level of our application.
We only go to the next level after the tests at the lower levels all pass.
If we then find that a test at a higher level fails, then we would first search for an error in the higher-level code.
Of course, it could also be that the tests at the lower level are either not sufficient and did not spot an error there that they themselves are wrong.
However, we do know a most likely source of an error.
This can tremendously speed up the process of locating and fixing bugs.

Testing also can very much increase our confidence in what we do.
We have not just written down this code.
We have tested it.
And we tested the code that uses this code.
And all tests pass.
Surely, there still might be undetected errors.
But we did cover the likely use cases with proper tests and they did work.
Our work is not just some fiddly bricolage, it is a piece of sound engineering.

But how does this work on a technical level?
It's easy.
A \pgls{unitTest} is basically a separate program.
This program loads the module and function it is supposed to test.
It invokes the function and compares its behavior to the expected behavior in a given scenario.
If it matches, the test passes.
If it differs, then the test fails.
Here, a \inQuotes{scenario} can be specific parameter values (arguments) and the \inQuotes{behavior} can be the return value of a function, for example.
We know which return value we expect for the given input and we compare the actual return value with that.
We can design arbitrarily many such scenarios~(test cases) for testing one function.
The tests are part of the software developement and the documentation.

The tests are normally not part of the final product~(the program) that ships to the customer or end users.
They have no real function beyond testing the actual and documenting the expected behavior of components.

Actually, we even \emph{almost} did this already.
Remember how we compared the result of our self-implemented \pythonil{sqrt} function with the \pythonilIdx{sqrt} function provided by the module \pythonil{math}?
We printed the values of both functions side-by-side.
We could also have compared programmatically.
We could have reported \inQuotes{Test Success!} if \pythonilIdx{isclose} for them yields \pythonil{True} and a \inQuotes{Test Error!} otherwise.

The goal of using \pglspl{unitTest} is to ensure that each unit of the software performs as expected.
Since tests can be developed along~(or even before!) the single functions are implemented, potential errors can be found early in the development process.
As the \pglspl{unitTest} focus on smaller, well, units, they can be less complex and easier to understand.
The consequent usage of \pglspl{unitTest} supports a modular and cleaner programming style, as it forces the developer to divide bigger programs into smaller pieces that can be invoked and tested in separation.

Finally, \pglspl{unitTest} are especially useful if an application is developed, improved, and maintained over a long time:
It is important that test cases are preserved and re-tested every time the software changes.
This way, we can discover if a change that we applied to an older piece of code breaks a \pgls{unitTest}.
In other words, we can detect if a change on some module has unanticipated consequences on other code, which may lead to unexpected and unwanted changes of the behavior our program.
Especially with its increased automation, e.g., due to \pgls{continuousIntegration}, \pglspl{unitTest} in software development have steadily gained importance during the past decades~\cite{W2000WISTAWIISH,TLG2006UTCU,R2006ASOUTP} and are an important cornerstone of \python\ software development~\cite{P2021PUTAAOAEUTIP,O2022PTWP,DG2020TIP}.%
%
%
\begin{figure}%
\centering%
\includegraphics[width=0.7\linewidth]{\currentDir/pipInstallPytest}%
\caption{Installing \pytest\ in a \ubuntu\ \pgls{terminal} via \pip~(see \cref{sec:pipAndVenv} for a discussion of how packages can be installed).}%
\label{fig:pipInstallPytest}%
\end{figure}%
%
Let us now test our code.
We will use \pytest\ for this, a \python\ framework for unit testing~\cite{KPDT2024PD}.
We install it by opening the \pgls{terminal} by either pressing \ubuntuTerminal\ under \ubuntu\ \linux\ or \ubuntuTerminal\ or under \microsoftWindows\ via \windowsTerminal.
As sketched in \cref{fig:pipInstallPytest}, we then type in \bashil{pip install pytest pytest-timeout}\pythonIdx{pip} and hit \keys{\return}.~(Normally, we would do that in a \pgls{virtualEnvironment}, which we discuss later in \cref{sec:pipAndVenv}.)
It is important that we install \emph{two} \python\ packages here:
The package \textil{pytest} offers the basic testing functionality.
The package \textil{pytest-timeout} allows us to limit the runtime of tests, which is a very important feature~(as you will see).%
%
\usefulTool{pytest}{%
\pytest\ is a \python\ framework for writing and executing software tests~\cite{KPDT2024PD}.
It can be installed via \bashil{pip install pytest pytest-timeout} as shown in \cref{fig:pipInstallPytest} on \cpageref{fig:pipInstallPytest}. %
You can then apply \pytest\ using the command \bashil{pytest --timeout=toInS file(s)}, where \textil{toInS} should be replaced with a reasonable timeout in seconds and \textil{file(s)} is one or multiple files with test cases. %
We provide a script for using \pytest\ with a reasonable default configuration in \cref{lst:bash:pytest} on \cpageref{lst:bash:pytest}. %
See also \cref{ut:doctest} later on.%
}%
%
You will ask yourself how testing and especially the reuse of test cases works.
It is, actually, fairly simple:
We have our actual program code in one or multiple \python\ files.
We have our test code in some other \python\ files.
For the same of clarity, if the actual code is in a file~\programUrl{functions:my_math}, then we could the code for the tests into a file called~\programUrl{test_my_math}.

\gitLoadPython{functions:test_my_math}{}{functions/test_my_math.py}{}%
\listingPython{functions:test_my_math}{%
A small \pgls{unitTest} suite for \cref{lst:functions:my_math}.}%
%
\gitExec{exec:functions:test_my_math:pytest}{\programmingWithPythonCodeRepo}{.}{_scripts_/pytest.sh functions test_my_math.py}%
\listingToolOutput{functions:test_my_math:pytest}{%
The output of the \pglspl{unitTest} in \cref{lst:functions:test_my_math}: While the test of \pythonil{factorial} succeeds, our \pythonil{sqrt} function fails for input~\pythonil{0.0}.}%

In \cref{lst:functions:test_my_math} we do just that.
We create a file \programUrl{functions:test_my_math} and into this file, we want to put the code for testing our module~\textil{my_math}.
This testing code is defined in form of functions.
The names of these functions must start with \textil{test_}.

Now our module \textil{my_math} provides two functions, \pythonil{factorial} and \pythonil{sqrt}.
At the top of our new tests module \textil{test_my_math}, we \pythonilIdx{import} both of these functions.
Naturally, we would create corresponding test functions and call them \pythonil{test_factorial} and \pythonil{test_sqrt}.
These functions have no parameters and no return values.

Tests are often defined in the form of several assertions assertions:\pythonIdx{assert}%
%
\pythonSyntax{syntax/assert.py}%
%
An assertion is defined by the keyword \pythonilIdx{assert} followed by an arbitrary Boolean expression.
If the Boolean expression evaluates to \pythonil{True}, then nothing happens.
If it evaluates to \pythonil{False}, then an \pythonilIdx{AssertionError} is raised.
This error will cause the test function to fail and terminate immediately.
We will learn in \cref{sec:exceptions} what \pythonilsIdx{Exception} are and how to handle them in detail.
If the complete test function runs through without raising any \pythonilIdx{Exception}, then the test has succeeded.
If it raises an \pythonilIdx{Exception} at any point during its execution, the test has failed.

Now we create the function \pythonil{test_factorial} to test the \pythonil{factorial} function.
For example, we know that $\factorial{0}=1$ and therefore it must be that \pythonil{factorial(0) == 1}.
So it makes sense to define \pythonil{assert factorial(0) == 1}.
The Boolean expression here is \pythonil{factorial(0) == 1}, which is obviously only \pythonil{True} if \pythonil{factorial(0)} evaluates to~\pythonil{1}.
We now manually compute some other factorials.
We thus can define similar cases for~\factorial{1}, \factorial{2}, and~\factorial{3}.

Obviously, we cannot write down a complete list of all possible inputs.
But these are the four smallest ones for which the factorial is defined.
Therefore, we test them.
By testing also \factorial{12}, we have checked \pythonil{factorial} for a mid-sized argument.
We then also create a test case for a fairly large number, say~\factorial{30}.
It is \emph{very} \emph{\textbf{very}} important that we did \emph{not} use our \pythonil{factorial} function to compute the expected return values {\dots} otherwise the whole test would make no sense at all.
Instead, we used some other tool.
Here, we have computed this value using an online calculator\footnote{\url{https://www.numberempire.com}} that offers arbitrary precision.
The result of \factorial{30} is more than~$265*10^{30}$, which is fairly beyond the range of 64~bit integers (and thus showcases that integers in \python~3 have an unlimited range, as stated back in \cref{sec:int}).
This test case validates whether our \pythonil{factorial} function works well for large numbers, too.

If our \pythonil{factorial} function passes all of these tests, we can be fairly certain that it is implemented correctly.
There could still be errors, though.
For example, we did not test~\factorial{4}.
But at least it looks unlikely that~\factorial{3} and~\factorial{12} \inQuotes{work,} but not~\factorial{4}.

For the \pythonil{sqrt} function, we create similar test function and call it \pythonil{test_sqrt}.
Reasonable test cases are \pythonil{assert sqrt(0.0) == 0.0}, \pythonil{assert sqrt(1.0) == 1.0}, and \pythonil{assert sqrt(4.0) == 2.0}.
We would also expect that \pythonil{sqrt(x) * sqrt(x) == x} for different~\pythonil{x}.
However, we have to account for the limited precision of the datatype \pythonilIdx{float} discussed in \cref{sec:howFloatingPointNumbersWork}.
Even if we would get as close to~$\sqrt{\pythonil{x}}$ for some~\pythonil{x} as possible, we can only represent 15 to 16 digits.
Therefore, we have to give a little bit of wiggle room when we compute \pythonil{s3 = sqrt(3.0)} and hope that \pythonil{s3 * s3 == 3.0}.
We do this by writing \pythonil{assert abs(s3 * s3 - 3.0) <= 5e-16}, i.e., by assuming that the difference between \pythonil{3.0} and \pythonil{s3 * s3} is not bigger than the very small number~$5*10^{-16}$.
On the other hand, the square root of \pythonil{1e10 * 1e10} should be representable exactly, namely as~\pythonil{1e10}.

The datatype \pythonilIdx{float} also offers us two special values, \pythonilIdx{inf} and \pythonilIdx{nan}, which both can be imported from the \pythonilIdx{math} module and which were discussed in \cref{sec:float:special}:
\pythonilIdx{inf}~stands for \inQuotes{too large to represent as \pythonil{float}} and is often interpreted as positive infinity~$+\infty$.
\pythonilIdx{nan}~stands basically for \inQuotes{undefined}, a value that you may get if you try to compute something like~\pythonil{inf - inf}.

Our \pythonil{sqrt} function has to understand and correctly handle these values as well.
\pythonil{sqrt(inf)} should again return~\pythonilIdx{inf}.
\pythonil{sqrt(nan)} should return~\pythonil{nan}.
However, we cannot do \pythonil{assert sqrt(nan) == nan}, since \pythonilIdx{==} will yield \pythonil{False} if at least one \pythonilIdx{nan} is involved (see again \cref{sec:float:special}).
For testing whether \pythonil{sqrt(nan)} yield~\pythonilIdx{nan}, we use the function~\pythonilIdx{isnan} from the \pythonilIdx{math} module.
This function returns \pythonil{True} for \pythonil{isnan(nan)} and \pythonil{False} otherwise.

With this, we have covered most reasonable inputs that either \pythonil{factorial} or \pythonil{sqrt} could receive.
We have defined what we would expect as output for these inputs.
These expectations are implemented as test cases.
Regardless of how \pythonil{factorial} or \pythonil{sqrt} are implemented, they should pass these test cases.
Otherwise, they are wrong.%
%
\begin{sloppypar}%
We now execute our tests.
We therefore open a \pgls{terminal} and type in the command \bashil{pytest --timeout=10 --no-header --tb=short test_my_math.py}.
The first part, \bashil{pytest}, invokes \pytest.
\bashil{--timeout=10} defines a time out of ten seconds.
If test runs longer than ten seconds, it will be aborted.
In this case, it is considered as failed.
\bashil{--no-header} and \bashil{--tb=short} are just there to tell \pytest\ to produce shorter, more succinct output.
I need them because otherwise, the listings with the output do not fit on a page.
You will normally not use these parameters.
Finally, \bashil{test_my_math.py} is the name of the file with the tests that we want to run.%
\end{sloppypar}%
%
Running our test cases with \pytest\ yields the output in \cref{exec:functions:test_my_math:pytest}.
This output tells us that \pythonil{test_factorial} ran through without any issue.
\pythonil{test_sqrt} however failed with a \pythonilIdx{ZeroDivisionError} that was raised inside our \pythonil{sqrt} function.
This happened when we tried to compute~\pythonil{sqrt(0.0)}.

We have to go back to our \pythonil{my_math} module in \cref{lst:functions:use_my_math} to find what is going wrong.
We see that our initial guess for the square root is~\pythonil{1}.
We set it via \pythonil{guess: float = 1.0}.
In each step, we then compute \pythonil{guess = 0.5 * (guess + number / guess)}.
If \pythonil{number} is \pythonil{0.0}, then this effectively means \pythonil{guess = 0.5 * guess}.
And because \pythonil{number} remains unchanged at \pythonil{0.0}, we repeat this step again and again.
\pythonil{guess}~is halved again and again.

We have learned that the precision of \pythonilsIdx{float} is finite and that positive values smaller than \pythonilIdx{5e-324}\pythonIdx{float!smallest} will just become~\pythonil{0.0}.
This will happen here too.
\pythonil{guess}~will thus eventually become~\pythonil{0.0}.
In the next iteration after that, this leads to us trying to divide~\pythonil{0.0 / 0.0}, causing the \pythonilIdx{ZeroDivisionError}.
%
\FloatBarrier%
\gitLoadPython{functions:my_math_2}{}{functions/my_math_2.py}{}%
\listingPython{functions:my_math_2}{%
An improved variant of \cref{lst:functions:my_math} dealing with the failing test case~\pythonil{0.0} discovered in \cref{exec:functions:test_my_math:pytest}.}%
%
\gitLoadPython{functions:test_my_math_2}{}{functions/test_my_math_2.py}{}%
\listingPython{functions:test_my_math_2}{%
We use the same small \pgls{unitTest} suite given in \cref{lst:functions:test_my_math} for \pythonil{sqrt} in \cref{lst:functions:my_math_2}.}%
%
\gitExec{exec:functions:test_my_math_2:pytest}{\programmingWithPythonCodeRepo}{.}{_scripts_/pytest.sh functions test_my_math_2.py}%
\listingToolOutput{functions:test_my_math_2:pytest}{%
The output of the \pglspl{unitTest} in \cref{lst:functions:test_my_math_2}: This time, we hit the timeout because of an endless loop!}

In order to fix this problem, we introduce the check \pythonil{if number <= 0.0} into our \pythonil{sqrt} function in the new version \programUrl{functions:my_math_2} of our module given in \cref{lst:functions:my_math_2}.
If this new conditional evaluates to \pythonil{True}, we return~\pythonil{0.0} directly.
Now we do not consider the case that a negative number is passed into \pythonil{sqrt} at this point.
In that case, we would ideally \pythonilIdx{raise} an error by ourselves, but we will learn only later how to do that.\footnote{%
We learn it in \cref{sec:exceptions} and there we will revisit our \pythonil{sqrt} function in \cref{lst:exceptions:sqrt_raise}, too.}

We apply the same tests to the new version of the \pythonil{sqrt} function as file \programUrl{functions:test_my_math_2} in \cref{lst:functions:test_my_math_2} to test our new module~\pythonil{my_math_2}.
The output of the test case, provided in \cref{exec:functions:test_my_math_2:pytest}, now indicates another error:
We get a timeout!

We invoked \pytest\ with the option \bashil{--timeout=10}, which only works if the package \textil{pytest-timeout} is installed.
This limited the maximum runtime of our test suite to ten seconds.
Ten seconds is a reasonable time for \emph{this book} as we actually run all the scripts automatically during the book building process.
In practical situations, you will usually choose a larger time limit.%
%
\bestPractice{testTimeout}{%
Always attach a timeout to your \pglspl{unitTest}. %
This timeout can be generous, maybe one hour, but it will serve as sentinel against either endless loops, deadlocks, or other congestion situations which all would be practical test failures. %
Timeouts protect automated builds or \pgls{continuousIntegration} systems from clogging.}%
%
\begin{sloppypar}%
We can see from the output of \pytest, that the timout occurred when the argument \pythonil{inf} was passed in as value for the parameter \pythonil{number} of our \pythonil{sqrt} function.
What could have happened here?
Again, we initially set \pythonil{guess = 1.0}.
In the first iteration of the loop in \pythonil{sqrt}, we compute \pythonil{guess = 0.5 * (guess + number / guess)}.
This is the same as \pythonil{guess = 0.5 * (1 + inf / 1)}, which is the same as \pythonil{guess = 0.5 * inf}.
This makes \pythonil{guess} become \pythonil{inf}, too.
Then, in the second iteration, we again have \pythonil{guess = 0.5 * (guess + number / guess)}.
This now is the same as \pythonil{guess = 0.5 * (inf + inf / inf)}.
And \pythonil{inf / inf} yields~\pythonil{nan}~\cite{G1991WECSSKAFPA}.
\end{sloppypar}%
%
The \pythonil{nan} infects the rest of the computation, and the result turns into \pythonil{guess = nan}.
From now on, all calculations yields \pythonil{nan}.
Now it holds that \pythonil{nan != nan} and \pythonil{isclose(nan, nan)} never becomes \pythonil{True}.
Therefore, our loop never ends.
The time limit protected us here.
Our \pythonil{sqrt} function goes into an endless loop if \pythonil{number = inf}.
And our \pgls{unitTest} would have run forever.

\gitLoadPython{functions:my_math_3}{}{functions/my_math_3.py}{}%
\listingPython{functions:my_math_3}{%
An improved variant of \cref{lst:functions:my_math_2} dealing with the failing test case~\pythonilIdx{inf} discovered in \cref{exec:functions:test_my_math_2:pytest}.}%
%
\gitLoadPython{functions:test_my_math_3}{}{functions/test_my_math_3.py}{}%
\listingPython{functions:test_my_math_3}{%
We use the same small \pgls{unitTest} suite given in \cref{lst:functions:test_my_math} for \pythonil{sqrt} in \cref{lst:functions:my_math_3}.}%
%
\gitExec{exec:functions:test_my_math_3:pytest}{\programmingWithPythonCodeRepo}{.}{_scripts_/pytest.sh functions test_my_math_3.py}%
\listingToolOutput{functions:test_my_math_3:pytest}{%
The output of the successful \pglspl{unitTest} in \cref{lst:functions:test_my_math_3}.}%
%
\begin{sloppypar}%
We solve this problem in the third version of our module, \programUrl{functions:my_math_3}, given in \cref{lst:functions:my_math_3}.
Here, we add a new condition: \pythonil{if not isfinite(number)}, we return \pythonil{number} as-is.
\pythonilIdx{isfinite} is another function from the \pythonilIdx{math} module.
It takes one parameter and it returns \pythonil{True} if it is a finite number.
\pythonilIdx{isfinite}~returns \pythonil{False} if its argument is \pythonilIdx{inf}, \pythonilIdx{-inf}, or~\pythonilIdx{nan}.
This means that condition can only become \pythonil{True} in our function for \pythonilIdx{inf} or \pythonilIdx{nan}, as we already return~\pythonil{0.0} if \pythonil{number <= 0.0}.
Thus, we return \pythonil{inf}~if the input of our function is~\pythonilIdx{inf}.
And this is right.
We also return \pythonilIdx{nan}~if the input is~\pythonilIdx{nan}.
And this is right too.
These are also the results that we would expect.%
\end{sloppypar}%
%
In \cref{lst:functions:test_my_math_3}, we apply our \pglspl{unitTest} to this new version of our \pythonil{sqrt} function.
As you can see in the output provided in \cref{exec:functions:test_my_math_3:pytest}, the tests now complete successfully.
This was a good example of how tests can help us to spot errors in our code.
When looking at \cref{lst:functions:use_my_math}, we certain assumed that all of our functions were implemented correctly.
However, \pytest\ has helped us to spot two erros.
We then fixed these errors.%
%
\bestPractice{functionUnitTest}{%
A function which is not \glslink{unitTest}{unit tested} is \emph{wrong}.%
}%
\bestPractice{goodUnitTestsParam}{%
Good \pglspl{unitTest} for a given function should cover both expected as well as extreme cases. %
For a parameter, we should test both the smallest and largest possible argument values, as well as values from its normally expected range.%
}%
\bestPractice{unitTestCoverage}{%
Good \pglspl{unitTest} for a function should cover all branches of the control flow inside the function. %
If a function does one thing in one situation and another thing in another situation, then both of these scenarios should have associated \pglspl{unitTest}.%
}%
%
Many junior programmers are not aware how important \pglspl{unitTest} are.
Being able to understand, design, and use \pglspl{unitTest} is one of the most important abilities in software development.%
%
\cquotation{GPBHKP2022SPPAF}{%
No single factor is likely responsible for \sqlite's popularity.
Instead, in addition to its fundamentally embeddable design, several characteristics combine to make \sqlite\ useful in a broad range of scenarios.
In particular, \sqlite\ strives to be:\par\relax[\dots]\par\relax%
\textbf{Reliable}.
There are over 600~lines of test code for every line of code in \sqlite~\cite{HWACIS:HO2023WKUOS}.
Tests cover 100\% of branches in the library.
The test suite is extremely diverse, including fuzz tests, boundary value tests, regression tests, and tests that simulate operating system crashes, power losses, \pgls{inOut}~errors, and out-of-memory errors.
Due to its reliability, \sqlite\ is often used in mission-critical applications such as flight software~\cite{HWACIS:HO2024HSIT}%
}%
%
\sqlite\ is the most used \pgls{SQL} \pgls{db} in the world.
It is installed in nearly every smartphone, computer, web browser, television, and automobile~\cite{WB2019RHSOOS,GPBHKP2022SPPAF,C20245YOQ}.
And its core developers mark reliability, shown by thorough tests, as one of the four reasons for that.

Tests are incredibly important.
And we have seen this here.
I think that to most of us, our original \pythonil{sqrt} implementation looked pretty fine.
Of course, we probably noticed that it won't handle negative numbers in a reasonable way, but this one we can set aside for when we can raise \pythonilsIdx{Exception} by ourselves.
I do not think that most of us saw the issue with \pythonil{0.0}.
And I also doubt that many predicted the endless loop for~\pythonil{inf}.
Or even had the values \pythonil{inf} and \pythonil{nan} on their radar as possible inputs.
Indeed, we may have only realized this issue once we began thinking about testing the possible inputs.
Well, even if you did realize all these problems long before me, the issue stands:
We can benefit tremendously from tests.%
%
\FloatBarrier%
\endhsection%
%
\hsection{Function Arguments: Default Values, Passing them by Name, and Constructing them}%
\FloatBarrier%
%
\gitLoadPython{functions:normal_pdf}{}{functions/normal_pdf.py}{}%
\listingPython{functions:normal_pdf}{%
Implementing the probability density function~(PDF) of the normal distribution as function with default argument values.\pythonIdx{pi}\pythonIdx{exp}\pythonIdx{sqrt}}%
%
\gitLoadAndExecPython{functions:use_normal_pdf}{}{functions}{use_normal_pdf.py}{}%
\listingPythonAndOutput{functions:use_normal_pdf}{%
Using the PDF of the normal distribution implemented in \cref{lst:functions:normal_pdf}.}{}%
%
After the discussion of \pglspl{unitTest}, let us now come to a lighter topic: passing arguments to functions.
We have already seen many examples for this.
Our \pythonil{gcd} function from back in \cref{lst:functions:def_gcd} has two parameters \pythonil{a} and \pythonil{b}.
We can invoke this function by writing the values of these parameters in parentheses after the function name.
\pythonil{gcd(12, 4)} will invoke \pythonil{gcd} and assign \pythonil{12} to \pythonil{a} and \pythonil{4} to \pythonil{b}.
What else can we do with parameters?

We can also let parameters have so-called \emph{default values}.\pythonIdx{function!parameter!default value}\pythonIdx{function!argument!default}
If a parameter has a default value, then specifying a value for the parameter when calling the function becomes optional.
Wee can specify the value of the parameter \emph{or} we can simply omit it, i.e., not assign a value to it.
In the latter case, the parameter will then have the default value.
From inside the function, this looks the same as if we passed in the default value.

As a simple example, let us implement the \pgls{mathPDF} of the normal distribution~\cite{AS1972HOMFWFGAMT,EHP2000SD,W2007HBOSDFE}.
You may remember from high school math that this function, let's call it~$f$, defined as%
%
\begin{equation}%
f(x, \mu, \sigma) = \frac{1}{\sqrt{2\numberPi\sigma^2}} \numberE^{\frac{-(x-\mu)^2}{2\sigma^2}}%
\label{eq:normalDistributionPdf}%
\end{equation}%
%
\begin{figure}%
\centering%
\includegraphics[width=0.65\linewidth]{\currentDir/normalDistPdf}%
\caption{A sketch of the \pgls{mathPDF} of the normal distribution given in \cref{eq:normalDistributionPdf}.}%
\label{fig:normalDistPdf}%
\end{figure}%
%
Here, $\mu$~is the expected value of the distribution and $\sigma$~is its standard deviation~(making $\sigma^2$~its variance).
$x$~is, so to say, the input value of this function.
It represents a value that a normally-distributed random variable could take on.
This function~$f$ describes typical bell-shaped curve of the normal distribution as sketched in \cref{fig:normalDistPdf}.
Implementing this function as a, well, function in \python\ is straightforward.
The \python\ file \programUrl{functions:normal_pdf} in \cref{lst:functions:normal_pdf}\pythonIdx{pi}\pythonIdx{exp}\pythonIdx{sqrt} offers the function \pythonil{pdf} with three parameters:~\pythonil{x}, \pythonil{mu}, and~\pythonil{sigma}, which represent~$x$, $\mu$, and~$\sigma$, respectively.%
%
\begin{sloppypar}\pythonIdx{function!call}%%
Now, with the two parameters~$\mu$ and~$\sigma$ of~$f$~(respectively~\pythonil{mu} and~\pythonil{sigma} of~\pythonil{pdf}), we can represent the general normal distribution.
The \emph{standard} normal distribution has~$\mu=0$ and~$\sigma=1$, i.e., is centered around the mean~$0$ and has a standard deviation~(and variance) of~$1$.
Very often, we want to compute the \pythonil{pdf} for the standard normal distribution.
We therefore define the \emph{default} values for \pythonil{mu} to be~\pythonil{0.0} and for \pythonil{sigma} to be~\pythonil{1.0}.
This is done directly in the header of the function.
Instead of writing \pythonil{x: float, mu: float, sigma: float}, we just have to write \pythonil{x: float, mu: float = 0.0, sigma: float = 1.0}.%
\end{sloppypar}%
%
Nothing changes regarding how the parameters are used inside the function.
We just use them completely normally, like any other parameter.
The function body does not know where their values come from.

In order to implement the \pgls{mathPDF} of the normal distribution, we first need to import the functions~\pythonilIdx{exp} and~\pythonilIdx{sqrt} from the module~\pythonilIdx{math} as well as the constant~\pythonilIdx{pi}.
Here, \pythonil{exp(x)} computes~$\numberE^{\pythonil{x}}$.
The term~$2\sigma^2$ appears twice in \cref{eq:normalDistributionPdf}, once under the square root in the first fraction and once in the fraction used in the exponent.
So we compute it once and store it in a variable~\pythonil{s2}.
This simplifies the equation to~$[\numberE^{-(x-\mu)^2 / \pythonil{s2}}]/[\sqrt{\numberPi*\pythonil{s2}}]$.
Notice how the power operator~\pythonil{a ** 2}\pythonIdx{**} is equivalent to~$\pythonil{a}^2$.

In program \programUrl{functions:use_normal_pdf} given in \cref{lst:functions:use_normal_pdf}, we import and use our new \pythonil{pdf} function.
When calling \pythonil{pdf}, we can omit the values of the parameters with default values, in which case they will take on their default values.
For example, invoking \pythonil{pdf(0.0)} is equivalent to calling~\pythonil{pdf(0.0, 0.0, 1.0)}.
We also can specify some of the parameters with default values while omitting others.
For instance, the function call \pythonil{pdf(2.0, 3.0)} is the same as \pythonil{pdf(2.0, 3.0, 1.0)}.
Obviously, we must always specify the first parameter~(\pythonil{x}), because it has no default value.

Default values do not need to be \pglspl{literal}.
They can also be the results of expressions, such as~\pythonil{sqrt(2.0)}.
However, they are only evaluated exactly once, when the function is defined~\cite{H2025PM:MDA}.
Then they are stored in the function header and reused whenever needed.
This has an interesting implication:
What if the default value for a function argument is mutable, say, a \pythonil{list} or \pythonil{set}?
Well, they never should be.
Because that could lead to awful problems~\cite{H2025PM:MDA}.
%
\bestPractice{defaultValues}{%
\pythonIdx{function!parameter!default value}\pythonIdx{function!argument!default}%
Default parameter values must always be immutable~\cite{H2025PM:MDA}.}%
%
The default value of a function argument must always be immutable.
If you would pass in, e.g., a \pythonil{list}, then the function could modify the list and the next call to this function would then receive this modified list.
Even worse, if the function was to return the list, it could be modified outside of the function.
The behavior of such code could become arbitrarily hard to debug.

In cases where a parameter is of a mutable type and we require a default value for it, we could instead use \pythonilIdx{None}.
Inside the function body, we could then check for \pythonilIdx{None} and implement appropriate behavior.%
%
\begin{sloppypar}%
Let's circle back to passing arguments to functions.
Assume that we have a function \pythonil{def g(x: int, y: int)}.
Normally, we would call it like~\pythonil{g(1, 2)}, in which case the function body sees \pythonil{x == 1} and \pythonil{y == 2}.
However, you can also pass in arguments very much in the same way that you use to assign a variable, in the form~\pythonil{parameterName=value}.
We could write \pythonil{g(x = 1, y = 2)} or, if we feel naughty, \pythonil{g(y = 2, x = 1)}.
Both variants will be equivalent to our original function call.
All we did is to explicitly write the names of the parameters when providing their values.%
\end{sloppypar}%
%
\pythonIdx{function!parameter!by name}\pythonIdx{function!argument!by name}%
We now revisit our \pythonil{pdf} function defined in file \programUrl{functions:normal_pdf} and used in \programUrl{functions:use_normal_pdf}, given in \cref{lst:functions:normal_pdf,lst:functions:use_normal_pdf}, respectively.
The function \pythonil{pdf} has a parameter \pythonil{x} without default value, followed by a parameter \pythonil{mu} with default value, which, in turn, is followed by a parameter \pythonil{sigma} with default value.
What would we do if we want to specify the value of the parameter \pythonil{sigma} of our function, but leave \pythonil{mu} at its default value?%
%
\begin{sloppypar}%
We can do this by passing in values by parameter name:
\pythonil{pdf(-2.0, sigma=3.0)}~passes in \pythonil{-2.0} for~\pythonil{x} and \pythonil{3.0} for~\pythonil{sigma}.
It does not specify any value for~\pythonil{mu}, leaving it at its default value.
This renders the call equivalent to~\pythonil{pdf(-2.0, 0.0, 3.0)}.
This passing in of arguments by specifying \pythonil{parameterName=value} also allows us to specify the arguments in arbitrary order.
\pythonil{pdf(mu=8.0, x=0.0, sigma=1.5)} is an example of this.
Don't do such things, though.%
\end{sloppypar}%
%
\begin{sloppypar}%
\Cref{lst:functions:use_normal_pdf} illustrates also another interesting way to call a function in \python.
As we have established by now, the parameters of a function have names.
We can write something like \pythonil{pdf(mu=8.0, x=0.0, sigma=1.5)} to assign arguments.
Calling \pythonil{pdf(-2.0, sigma=3.0)} is equivalent to writing~\pythonil{pdf(x=-2.0, sigma=3.0)}.
Passing arguments to a function basically means to a assign values to keys~(the parameters).
This is at least a little bit similar to the creation of a dictionary \pglspl{literal}.%
\end{sloppypar}%
%
In fact, \python\ allows us to also construct the arguments for a function call in a collection.
We can create a dictionary with the values \pythonil{\{"x": -2.0, "sigma": 3.0\}}.
Let's store this dictionary in variable~\pythonil{args_dict}.
Can we now somehow pass in the key-value pairs from \pythonil{args_dict} as parameter-argument pairs to~\pythonil{pdf}?

Indeed, we can.
We just have to write~\pythonil{pdf(**args_dict)}.\pythonIdx{**!function parameter}\pythonIdx{function!parameter!**}\pythonIdx{function!argument!**}\pythonIdx{function!argument!keyword}\pythonIdx{dict}
Doing this will unpack the dictionary \pythonil{args_dict} and pass all the values under their assigned names in as arguments to their corresponding parameters.
\pythonil{pdf(**args_dict)} is thus equivalent to~\pythonil{pdf(x=-2.0, sigma=3.0)}.

Two things are to notice here:
First, the double~\pythonil{*}\pythonIdx{*!function parameter}\pythonIdx{function!argument!*}\pythonIdx{function!parameter!*}.
The \pythonil{*} here is often called %
wildcard\pythonIdx{wildcard}\pythonIdx{function!argument!wildcard}\pythonIdx{function!parameter!wildcard}, %
star\pythonIdx{star}\pythonIdx{function!argument!star}\pythonIdx{function!parameter!star} or %
asterisk\pythonIdx{asterisk}\pythonIdx{function!argument!asterisk}\pythonIdx{function!parameter!asterisk}. %
The double-wildcard \pythonil{**} is written \emph{before} the dictionary.
The~\pythonil{**}\pythonIdx{**!function parameter} is telling \python\ to unpack the dictionary this way.
Second, default argument values still apply here.
We did not specify a value for~\pythonil{mu}.
This means that \pythonil{mu} will have value~\pythonil{0.0} in this function call.

Maybe we do not want to pass in the arguments by parameter names but simply by position.
Actually, we have always done it like this in the past.
Then, we can construct a sequence, e.g., a \pythonilIdx{list} or \pythonilIdx{tuple} with the parameter values.
Of course, \pythonilsIdx{list} and \pythonilsIdx{tuple} do not store key-value relationships, only values at positions.
We could create a tuple~\pythonil{args_tuple} with the value~\pythonil{(-2.0, 7.0, 3.0)}.

Then, we  invoke \pythonil{pdf} like this:~\pythonil{pdf(*args_tuple)}.
This will basically fill in the (three) values from the \pythonil{tuple} one by one into the parameter slots of the function.
In other words, this is equivalent to writing~\pythonil{pdf(-2.0, 7.0, 3.0)}.

This time, only a single wildcard~\pythonil{*}\pythonIdx{*!function parameter}\pythonIdx{function!argument!*}\pythonIdx{function!parameter!*} is placed before~\pythonil{args_tuple}.
We can also pass the parameters in by \inQuotes{unpacking} a list.
In our example \cref{lst:functions:use_normal_pdf}, we create the list \pythonil{args_list = [2.0, 3.0]}.
Calling~\pythonil{pdf(*args_list)} then is the same as writing~\pythonil{pdf(2.0, 3.0)}, which, in turn, is identical to~\pythonil{pdf(2.0, 3.0, 1.0)}.
Again, parameters with default values do not need to be supplied.

At first glance, the use of all of the above is not entirely clear.
What do we need default parameter values for?
Well, in some cases, you may want to enable a user to \inQuotes{customize} your functions.
A typical example is the \href{https://matplotlib.org/stable/api/_as_gen/matplotlib.axes.Axes.plot.html}{\pythonilIdx{plot} method} of the \pythonilIdx{Axes} object provided by popular \matplotlib\ library.
You will normally provide sequences of x-\ and y\nobreakdashes-coordinates to this function it will draw a line which goes through all the points specified this way.
However, you can also optionally specify a color for the line, markers to be painted at the points, line dash style, a label, colors and sizes for the markers, a z\nobreakdashes-order to be used if multiple lines are drawn, and so on, and so on.
The use of default arguments allows the function call to be relatively simple in most cases, while still allowing the user to do more complex formatting if need be.

From this example, we can also directly extrapolate a use case for building the arguments of a function in a dictionary.
Imagine that you write an own function that uses one of the plotting methods of \matplotlib.
Let's say that your function does a plot call where it provides ten parameter values.
However, you have one special case where you need to provide one more parameter, maybe a line dash style that you otherwise do not need to provide.
Then, you could have some \pythonil{if ... else} in your code that branches to do the ten-parameter-call in one case and the eleven-parameter-call in the other.
This means that a rather complex function call appears twice in a very similar manner.
If you instead construct a dictionary with the ten parameters.
In the \pythonil{if} branch just add the eleventh parameter if need be.
We now only need a single function call using the double-wildcard method.
The code will become much simpler.
The difference between the two cases will also be much more obvious.
We have reduced the potential for errors significantly.

With the default parameter values and function calls via \pythonil{*} and \pythonil{**}, we learned two more aspects that make it easier for us to work with functions in \python.
With the default values, we can now design more versatile function-based \pglspl{API} that allow the user of our function to provide values for some parameters, while leaving others at reasonable default settings.
By constructing arguments in collections, we can create code that is easier to read when we deal with functions with many arguments that may be called slightly differently depending on the situation.%
\FloatBarrier%
\endhsection%
%
\hsection{Functions as Parameters, \texttt{Callable}s, and \texttt{lambda}s}%
\label{sec:functionsAsVarsAndLambdas}%
%
We have learned how to define and call functions.
We learned how functions can return their results.
We learned how to test functions.
And we just learned that we can basically construct a function call by placing the parameter values into collection objects and then invoke the function by \inQuotes{unpacking} the collection using either~\pythonil{*}~(for position-based parameters) or~\pythonil{**}~(for dictionaries).
But there is one more interesting thing that we can do with functions.
You see, in \python, all things are objects~\cite{H2025PM:EIAO,PSF:P3D:TPLR:DM}.
References to objects can be stored by variables or passed in as function arguments.
Functions are objects too~\cite{H2025PM:EIAO}.
This means that we can also store functions in variables or pass them as argument to other functions!

At first glance, this sounds awfully odd.
Why would someone like to pass a function as parameter to another function?
At second glance, there are a wide variety of situations where we would actually want to do that.
Having done so many mathematics-based examples in this book, let's pick one such situation arising in maths.

In high school, you have learned about integration and differentiation.
A \emph{definite integral} is the formal calculation of the area under a function over a certain range along the \pgls{xAxis}.
It uses \pgls{infinitesimal}~\cite{EOWM2025MWAMTD:I,KS2013LITFTMIATFFBTRAB} stripes over the region to do so.

The second\footnote{%
Depending on the source, sometimes this is also called the first fundamental theorem of calculus~\cite{W2024MAWWR:SFTOC}.%
} %
fundamental theorem of calculus states~\cite{W2024MAWWR:SFTOC,A1991C:1:PFATSFTOC}:
Given a function~$f(x)$ which is continuous over the real interval~$[a,b]$ and its antiderivative~$F(x)$, the definite integral $\int_a^b f(x)\,dx = F(b)-F(a)$~(where antiderivative means that~$F'=f$).
In other words, if we want to get the area beneath~$f(x)$ over the interval~$[a,b]$, we would first obtain the antiderivative and then simply calculate~$F(b)-F(a)$.

Obtaining the antiderivative involves pen-and-paper symbolic maths.
We cannot really program such maths at this stage in this book as an example.
But we can go back to the original definition of the definite integral, namely that it equals the area beneath the function over the interval~$[a,b]$.
This area can obtained by using \pgls{infinitesimal}~(read:~immeasurably small) strips of the region.

While we cannot really use \inQuotes{immeasurably small} strips, we could use \inQuotes{fairly small} ones to approximate the right result.
Let's say that we have a function~$f(x)$ as a parameter of our program.
We would also have the interval limits~$a$ and~$b$ as parameters.
Then we could divide the range~$[a,b]$ into $n$~strips.
For each strip, we could approximate the area beneath~$f(x)$.
Then we add up the $n$~areas, and have a rough approximation of the total area.
$n$~could be another parameter for our integration approach.
The larger~$n$, the smaller will the strips get, the more accurate should our estimate become~(and the longer it will take to get it).%
%
\begin{figure}%
\centering%
\includegraphics[width=0.65\linewidth]{\currentDir/normalDistPdfInteg}%
\caption{A sketch of the composite trapezoid method for approximating definite integrals.}%
\label{fig:normalDistPdfInteg}%
\end{figure}%
%
\gitLoadAndExecPython{functions:integral}{}{functions}{integral.py}{}%
\listingPythonAndOutput{functions:integral}{%
Using the composite trapezoid method to numerically approximate definite integrals, as sketched in \cref{fig:normalDistPdfInteg}.}{}%

This brings us to the question how we can do this, in particular, how to approximate the area of one such strip.
The composite trapezoid method is one very simple implementation of this idea~\cite{S2021ITNM:NIATROTTR,E2013AITNMAA,A1991AITNA}.
As illustrated in \cref{fig:normalDistPdfInteg}, it treats the strips as right trapezoids.
The baseline of the trapezoid is a piece of the \pgls{xAxis} with length~$h=(b-a)/n$.
Clearly, $n*h=b-a$ and thus, $n$~trapezoids of equal base length form the range of the \pgls{xAxis} under~$f(x)$.
The baseline first trapezoid starts right at~$x=a$ and extends to~$x=a+h$.
The second trapezoid starts at~$x=a+h$ and extends to~$x=a+2h$.
The last trapezoid starts at~$x=a+(n-1)h$ and extends to~$x=a+nh=b$.
Each trapezoid has two parallel sides meeting with its baseline in right angles.
The length of these sides are the values of~$f(x)$ at the corresponding x\nobreakdashes-coordinate.
The area of the $i$\nobreakdashes-th trapezoid is thus~$h[f(a+(i-1)h)+f(a+ih)]/2$.
Summing up the $n$~areas yields an approximation of the definite integral, as sketched in \cref{fig:normalDistPdfInteg}.

Each value~$f(a+ih)$ except for $i=0$ and $i=n$ appears twice in the sum and each time is halved.
Instead of computing these values twice, dividing them by two, and then adding them, we can simply compute them only once.

We want to implement this method as a function \pythonil{integrate}.
Obviously, \pythonil{integrate} has the parameters \pythonil{a} and \pythonil{b} denoting the limits of the interval to integrate over.
We allow them to be either \pythonil{int} or \pythonils{float}, denoted by the \pgls{typeHint} \pythonil{float | int}.
Let's give them the default values \pythonil{0.0} and \pythonil{1.0}, respectively.
Then there is the parameter \pythonil{n}, an \pythonil{int}, denoting the number of trapzes we need to construct.
A good default value for it may be \pythonil{100}.
But we need another parameter, namely the function \pythonil{f} that we want to integrate.
How can we specify this parameter?

The answer is given as program \programUrl{functions:integral} shown in \cref{lst:functions:integral}.
The most interesting part of our \pythonil{integrate} function is its header.
More precisely, it is the first parameter:~\pythonil{f: Callable[[float], float | int]}\pythonIdx{Callable}\pythonIdx{typing}.
\pythonilIdx{Callable} is the \pgls{typeHint} for anything that can be called, i.e., functions~\cite{PSF:P3D:TPSL:ACO}.
Like the \pglspl{typeHint} for lists and tuples, it can be parameterized following a scheme with square braces~\cite{PEP612}:%
%
\pythonSyntax{syntax/callable.py}%
%
Inside the \pythonil{Callable[...]}, we first provide the list of types of the parameters of function, again in square brackets.
Then follows a comma~\pythonil{,} and then follows the return type.
The \pythonil{f: Callable[[float], float | int]} in our listing thus states that our function \pythonil{integrate} expects, as first parameter, \emph{another function}~\pythonil{f}.
\pythonil{f}~must accept one parameter of type~\pythonil{float}.
The return type of~\pythonil{f} is \pythonil{float | int}, i.e., it should return either a~\pythonil{float} or an~\pythonil{int}\pythonIdx{\textbar!type hints}~\cite{PEP604}.
Notice that the type \pythonilIdx{Callable} is provided by the module~\pythonilIdx{typing}\footnote{%
\cite{PSF:P3D:TPSL:ACO}~states that this import is now deprecated and we should use \pythonil{collections.abc.Callable}\pythonIdx{collections.abc} instead. %
In the past, this created some errors for me, so for now we stick with using~\pythonilIdx{typing}.}, %
so we need to import it first if we want to use it.

The actual implementation of \pythonil{integrate} is straightforward.
Inside the function, we add up the different trapezes as shown in the simplified equation in \cref{fig:normalDistPdfInteg}.
Only the values of \pythonil{f} at the interval ends \pythonil{a} and \pythonil{b} need to be halved in the sum.
We therefore initialize the sum \pythonil{result} as \pythonil{0.5 * (f (a) + f(b))}.
We compute the trapez base length~\pythonil{h} as~\pythonil{(b - a) / n}.
Then we iterate counter~\pythonil{i} from \pythonil{1} to \pythonil{n - 1} and add \pythonil{f(a + h * i)} to \pythonil{result} in each step.
Finally, we return need to multiply this with the trapez base length~\pythonil{h} to get the approximation of the area under the curve.
We thus return \pythonil{result * h}.

Let's now test how well our trapezoid-based integration works.
First, let's compute the definite integral~$\int_0^1 1\,dx$.
For this purpose, we need to pass the function~$f(x)=1$ as the~\pythonil{f} parameter of~\pythonil{integrate}.
We could do this by writing:%
%
\pythonSyntax{syntax/const_unary_function.py}%
%
where the \pythonil{_}\pythonIdx{\_} indicates that we are actually going to ignore this parameter~(see~\cref{bp:underscore}).
We could then invoke~\pythonil{integrate(const_1)}.

However, there also is a more compact way to specify functions that we are only going to use once:
The so-called \pythonilsIdx{lambda}~\cite{PSF:P3D:TPLR:L}, nameless functions defined inline, which have the structure%
%
\pythonSyntax{syntax/lambda.py}%
%
This inline function definition begins with the keyword \pythonilIdx{lambda}.
Then, the names of the parameters follow~(if any), separated by commas~\pythonil{,}.
Then there is a colon~\pythonil{:}, after which an expression computing the return value of the inline function follows.
The special thing about \pythonils{lambda} is, that their body only consists of this single expression.
They are basically a single line of code with the only purpose to compute a return value.
Due to the \pythonilIdx{:} in the notation, we cannot annotate \pythonilsIdx{lambda} with \pglspl{typeHint}.
As a \pythonil{lambda} expression is very small and only used once, this does not pose a serious problem.

We now need to define a function returning the constant~\pythonil{1} as \pythonilIdx{lambda}.
This function must accept one parameter, because otherwise we cannot plug it into \pythonil{integrate}.
Since we do not care about the value of this parameter, we can simply write:%
%
\pythonSyntax{syntax/lambda_as_arg.py}%
%
\pythonilsIdx{lambda} are functions that we only want use in a single place.
This is clearly the case for a function that ignores its parameter and always returns~\pythonil{1.0}.
So we pass this expression into our \pythonil{integrate} function as value of the parameter~\pythonil{f}.

Obviously, the area under the constant function~$f(x)=1$ over the range~$[0,1]$ is also~$1$.
Our function \pythonil{integrate} thus has passed a first sanity test.
Using \pythonil{n=7} trapezoids, we get exactly this result.
In the output of our program, we write~\inlinelistingbox{$\int$\lstinline[style=text_style]$1dx|0,1$} where the~\textil{|0,1} denotes the limits~$[0,1]$ of the interval over which we integrate.
We use the \pgls{unicode} \pgls{escapeSequence} \pythonil{"\\u222b"} to represent the~$\int$~character in the \pglspl{fstring}.

Having passed this simple sanity test, let's try to compute the beneath under the function~$g(x)=x^2-2$ over the interval~$[-1,1]$, i.e.,~$\int_{-1}^1 x^2-2\,dx$.
The antiderivative of~$g(x)$ is~$G(x)=\frac{1}{3}x^3-2x+c$ and $G(1)-G(-1)=[\frac{1}{3}-2]-[-\frac{1}{3}+2]=\frac{2}{3}-4=-3\frac{1}{3}=-3.\overline{3}$.
We pass the function~$g(x)$ as \pythonilIdx{lambda} expression into our \pythonil{integrate} function by writing~\pythonil{lambda x: x*x - 2}.
We also need to specify a value for the parameter~\pythonil{a}, namely~\pythonil{-1}.
Using the default value of \pythonil{n=100} steps, our function returns~\pythonil{-3.3332}, which is fairly close to~$-3.\overline{3}$.

We now integrate the sine function over the interval~$[0,\numberPi]$.
We can import~\pythonilIdx{sin} from the \pythonilIdx{math}~module and pass it into our function for~\pythonil{f}.
We also need to specify \pythonil{b = pi}\pythonIdx{pi}, which we, too, have imported from~\pythonilIdx{math}.
This time, we use \pythonil{n = 200} trapezoids to approximate the definite integral.
The antiderivative of~$\sin x$ is~$-\cos x+c$, so the expected output would be~$[-\cos\pi]-[-\cos 0]=[-(-1)]-[-1]=2$.
Indeed, our function delivers about~$1.99996$, which is, again, fairly close.

As final example, we also integrate the \pgls{mathPDF} of the normal distribution.
We implemented this function and called it \pythonil{pdf} back in \cref{lst:functions:normal_pdf}, so we just need to \pythonilIdx{import} it from there.
Notice that this function actually had three parameters, \pythonil{x}, \pythonil{mu}, and~\pythonil{sigma}.
The latter two had the default values~\pythonil{mu = 0.0} and~\pythonil{sigma = 1.0}.
If these default values are used, the function computes the \pgls{mathPDF} of the \emph{standard} normal distribution.

\gitExec{exec:functions:integral:mypy}{\programmingWithPythonCodeRepo}{.}{_scripts_/mypy.sh functions integral.py}%
\listingToolOutput{functions:integral:mypy}{%
The results of static type checking with \mypy\ of the program given in \cref{lst:functions:integral}.}

Interestingly, although we demand that the function~\pythonil{f} supplied to \pythonil{integrate} should only have one parameter, we can still pass in~\pythonil{pdf} with its three parameters as~\pythonil{f}.
This is possible because its second and third parameter are optional.
Even \mypy\ accepts this function as valid parameter, as its output~(or better, the lack of it) in \cref{exec:functions:integral:mypy} suggests.

The standard normal distribution has standard deviation~$\sigma=1$ and mean~$\mu=0$.
If we integrate it over the interval~$[-1,1]$, we basically compute the probability that a standard normally distributed random variable~${\mathcal{X}}$ is drawn from the interval~$[\mu-\sigma,\mu+\sigma]$, i.e., from within one standard deviation from the mean.
As you may still know from high school math, this probability is roughly~68.26\%~\cite{AS1972HOMFWFGAMT,EHP2000SD,W2007HBOSDFE}.
Similarly, the probability that such a random variable is sampled from within~$[-2,2]$, i.e., not more than two standard deviations away from the mean, is about~95.44\%~\cite{AS1972HOMFWFGAMT,EHP2000SD,W2007HBOSDFE}.
The output of our little integrator function in \cref{exec:functions:integral} fits perfectly to this.

As a final clarification, let us mention that trapezoid-based approximation of definite integrals is by no means the best approach.
Others methods, like Simpson's rule, may often provide better results~\cite{E2013AITNMAA}.
Still, as an example of functions that work on other functions, it was suitable.%
\FloatBarrier%
\endhsection%
%
\hsection{Summary}%
Functions are the central building block needed to create modular code.
They allow us to put code into units with clearly defined interfaces.
The input of a function are its parameters~(if any).
The output is its return value~(if any).
Both parameters and return value can be annotated with \pglspl{typeHint}.
The description of what the function does as well as what the parameters and the return value mean, goes into the \pgls{docstring}.

This clear definition and separation from the rest of the code has several advantages.
First, multiple programmers can work together on a project.
They can work on different functions, which we can place into different modules~(\python\ files).
If we did not have functions available, this would be impossible.

Second, by using proper \pglspl{typeHint} for the function parameters and return value as well as proper \pglspl{docstring}, the behavior of functions is easier to understand by fellow programmers.
Type checkers like \mypy\ can also verify whether functions are called with correct parameters more easily.
The code does not just become more modular, but easier to maintain.
It can be checked by static code analysis tools as well.

Third, functions allow us to reuse pieces of code in different locations.
If we want to compute the definite integral of two different functions, we do not have to implement two routines for integration.
We can make one and use it in two different locations.

Fourth, if we have a function with clearly defined input parameters and output results, then we can \emph{test} this function in isolation.
It may be extremely difficult to test a complete program.
However, it may be rather straightforward to test a small function.

\Pglspl{unitTest}, for example using the \pytest\ framework, allow us to do just that.
It is also not hard to imagine that \pglspl{unitTest} can compound our trust into our code:
In the previous sections, we developed a function~\pythonil{pdf} for computing the probability density function of the normal distribution and a function~\pythonil{integrate} for approximating definite integrals.
Assume that we properly applied \pglspl{unitTest} to these two functions and have shown for both of them that they produce the expected results for a wide range of different inputs.
It would be easy to see that this then would also give us a certain confidence that using \pythonil{integrate} to compute a definite integral over a certain input range of~\pythonil{pdf} should be correct, too.
This could be verified with some additional \pglspl{unitTest}.
Working our way up from testing small components to larger and larger building blocks of an application gives us a good chance to have only few bugs in the final product.

These are a lot of advantages of using functions.
But functions in \python\ also come with lots of nice features as well.

For example, we can specify default values for function parameters.
This allows us to create functions that can be invoked using only few arguments in the normal case and that can be customized with more parameters in special cases.
Since functions themselves are objects, they can be stored in variables and parameters as well.
The proper \pgls{typeHint} for such variables or parameters is defined using the~\pythonilIdx{Callable} type.
Functions that accept \pythonilsIdx{Callable} as parameter can also accept \pythonilsIdx{lambda}.
\pythonilsIdx{lambda} are an abbreviated way to define functions, usually in a single line and only for a single use.%
\endhsection%
%
\endhsection%
%
